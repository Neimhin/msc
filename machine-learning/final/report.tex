%% LyX 2.3.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[10pt]{article}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2cm,bmargin=4cm,lmargin=2cm,rmargin=2cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}
\usepackage{tcolorbox}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{graphicx}
\usepackage[backend=biber,maxbibnames=99]{biblatex}
\addbibresource{main.bib}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tcolorbox}
\usepackage{amsthm}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{accents}
\usepackage{titlesec}
\usepackage{marginnote}
\usepackage{titlesec}
\titleformat{\section}[block]{\normalfont\bfseries}{}{0em}{}


\usepackage{enumitem}
\usepackage{comment}
\setlist{nolistsep}

\usepackage{tcolorbox}
\definecolor{light-blue}{cmyk}{0.24, 0.12, 0.0, 0.04, 1.00}
\titlespacing\section{0pt}{0pt}{0pt}
\titlespacing\subsection{0pt}{0pt}{0pt}
\titlespacing\subsubsection{0pt}{0pt}{0pt}

\setlength{\headheight}{40pt}

\makeatother

\begin{document}
\lhead{Neimhin Robinson Gunning} \rhead{CS7CS4 Final Assignment}

\section{DublinBike Usage}
\subsection{Engineering a ``usage'' feature}
The dublin bike dataset used for this analysis consists
of snapshots of station occupancy at five-minute intervals.
Because of this it is not possible to determin from the
dataset the exact number of times bikes have been
returned to or taken from a station.
We can look at the difference in bike occupancy at the
beginning and end of a five minute interval to establish
a {\em lower-bound} on the number of interactions with
the station, but it is possible for there to have been
more interactions (returns or borrowings) than this difference.
For instance, it may be that a bike station has 10 bikes at time $t$
and 10 bikes at time $t+5\text{m}$, but that in fact 5 bikes were
borrowed and 5 bikes were deposited.

But, we can detect such cases, because the dataset also includes a
\textsc{last updated} field. If the occupancy is not changed, but 
the time of last update is between the start and end of the interval,
then we know that there were at least 2 interactions with the bike station.

\section{Short Questions}
\subsection{(i)}
What is an ROC curve?

The name Receiver Operating Characteristic (ROC) is not very enlightening as to what an ROC curve is.

Often, a binary classifier consists of a function $c:X\rightarrow [0,1]$ which maps an input $x\in X$ to a the
probability that $x$ belongs to either of the classes. We can use this probability to make
a more concrete classification decision by selecting a threshold $\alpha$. For example:
\begin{equation}
\hat y(x)=
    \begin{cases}
        1 & \text{if } c(x) > \alpha, \\
        0 & \text{otherwise}
    \end{cases}
\end{equation}
Our choice of $\alpha$ changes the ultimate classification decisions.
For each choice of $\alpha$ we can calculate the True Positive Rate and False Positive Rate
of the classifier on a test data set, therefore we implicitly have a function $f:[0,1]\rightarrow \mathbb{R}^2$.
An ROC curve is a plot of the output values of this function $f$, i.e. the ROC plot generally does not
encode $\alpha$, only the output points $(\text{FPR},\text{TPR})$, so we
visualise the function $f$ as if it were a function $g:\text{FPR}\rightarrow \text{TPR}$.

\begin{equation}
    \begin{aligned}
        \text{TPR} & = \frac{\text{TP}}{\text{P}} & & \text{FPR} & = \frac{\text{FP}}{\text{N}}
    \end{aligned}
\end{equation}

The ROC curve $g$ will be monotone increasing from $0$ to $1$, but not smooth.
The `steps'
in an ROC curve occur where a small change in $\alpha$ result
in a change in classification of a single data point.

\textbf{How can it be used to evaluate the performance of a classifier?}

If the test set is fair then a `coin-flip' classifier, that just makes a random
classification for each input, will have an ROC curve approximating the line from $(0,0)$ to $(1,1)$,
with more data points giving a closer approximation. In this way the ROC curve lets you
implicitly compare a binary classifier to a `coin-flip` classifier.

In general a classifier is better if the area under the ROC curve is greater, where the maximum area is 1.
Being reductionist, this means that a classifier is better if it's ROC curve gets closer to the point the $(0,1)$.

\textbf{Why would you use an ROC curve instead of a classification accuracy metric?}
If the cost of different types of errors (false positive, false negative) are significantly
different for the particular use-case, or if the dataset is imbalanced,
then an ROC curve can be more illuminating than a reductionist accuracy metric
for evaluating whether specific requirements are being met, and it can be used to
search for the threshold $\alpha$ which balances the requirements of the task most appropriately.

\subsection{(ii)}
Linear regression will give inaccurate predictions when the target values are
not linearly correlated the input features.
For example if the target output is strongly correlated to the distance
of the input features from some point, i.e. there is a circular/spherical pattern,
then a linear regression will likely give poor predictions for a large
proportion of the data. Depending on the type of non-linearity between the
inputs and outputs it may be possible to augment the input features, e.g. by taking polynomial
combinations of the input features, such that the targets do become
linearly correlated with some subset of the augmented input features.
If this type of feature engineering doesn't work then a different model
that can handle non-linearity, such as a k-NN regression model,
could be used instead.

Linear regression can be sensitive to outliers,
where I define an outlier to be a datapoint which was generated
by some process distinct from expected process, i.e. a typo,
a faulty sensor.

\includegraphics{fig/outlier_example_linear_regression.pdf}

\subsection{(iii)}

\bigskip{}
\printbibliography
\end{document}
